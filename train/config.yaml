# config.yaml
dataset_file: "utn_nuernberg_dummy.json"
model_name: "Qwen/Qwen2.5-0.5B-Instruct"
output_dir: "./qwen2.5-0.5b-utn-lora"
max_length: 512

# Training hyperparameters
evaluation_strategy: "no"
learning_rate: 0.0002
per_device_train_batch_size: 1
num_train_epochs: 1
weight_decay: 0.01
save_total_limit: 1
logging_dir: "./logs"
logging_steps: 1
do_eval: false

# LoRA parameters
lora_r: 8
lora_alpha: 32
lora_dropout: 0.1
lora_bias: "none"
lora_target_modules:
  - "q_proj"
  - "v_proj"
