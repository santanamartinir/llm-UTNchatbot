# config.yaml
dataset_file: "data/q_a/UTN_q_a_merged.jsonl"
model_name: "models/Qwen2.5-0.5B-Instruct" # model name or path 
output_dir: "./lora_20_epochs_akash"
max_length: 512

# Training hyperparameters
evaluation_strategy: "no"
learning_rate: 0.0002
per_device_train_batch_size: 1
num_train_epochs: 20
weight_decay: 0.01
save_total_limit: 1
logging_dir: "./logs"
logging_steps: 1
do_eval: false

# LoRA parameters
lora_r: 8
lora_alpha: 32
lora_dropout: 0.1
lora_bias: "none"
lora_target_modules:
  - "q_proj"
  - "v_proj"
